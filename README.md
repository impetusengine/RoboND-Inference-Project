# RoboND-Inference-Project

Two exercises are implemented on Nvidia's DIGITS deep learning GPU training system. First, object classification is performed on a neural network trained on images of candy boxes and bottles photographed on a conveyor belt. This network is called P1 model. Second, a comparison is made between a neural network trained on images of numerically distinguished groups of three dimensional objects called RealModel and a neural network trained on images of numerically distinguished groups of two dimensional shapes called FlatModel. This pair of networks are tested on a testing set called RealTest which contains images of groups of three dimensional objects and a testing set called FlatTest which contains images of groups of two dimensional irregular shapes to investigate each network's accuracy in classifying the number of objects or shapes in an image. Realization of accurate classification for numerical abstraction is achieved on RealModel which successfully recognized number in both testing sets: RealTest and FlatTest. On the other hand, FlatModel failed to classify members of RealTest but succeeded to classify images of FlatTest. 

P1 model is trained and tested on a supplied data set not shown here. An example of what the data looks like is given in Inference_write_up.pdf. The folders seed_numbers_data and seed_numbers_test contain example images of each number class which are augmented to generate training and testing data for FlatModel and RealModel. FlatModel is trained on images generated from augmenting the samples in seed_numbers_data. RealModel is trained on a subset of images not set aside of testing that is generated from augmenting the images contained in the folder real_world which is contained in the folder seed_number_test. FlatTest is generated by augmenting the images in flat_land which is contained in seed_numbers_test. RealTest is the percentage of the data set aside for testing that was the augmented data that was partially generated to train RealModel. Details of the project are given in the report Inference_write_up.pdf. Finally, the folder screenshots contains images of results including loss and accuracy graphs and confusion matrices.   
